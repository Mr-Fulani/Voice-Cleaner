# Voice Cleaner

Инструмент для улучшения разборчивости речи в видеофайлах с использованием DSP (Digital Signal Processing) фильтров через ffmpeg.

## Описание задачи

Voice Cleaner обрабатывает видеофайлы, применяя адаптивные аудио фильтры для:
- Улучшения разборчивости речи
- Снижения фонового шума
- Выравнивания динамики
- Частотной коррекции речевого диапазона

**Важно:** Инструмент НЕ удаляет музыку полностью. Полное удаление музыки без source separation невозможно с помощью только DSP фильтров.

## Ограничения и допущения

### Технические ограничения
- Используется только `ffmpeg`, `ffprobe` и стандартная библиотека Python
- Без ML-моделей, без интернет-доступа
- Всё должно запускаться в Docker

### Инженерные допущения
- **Полное удаление музыки невозможно** без source separation (требует ML)
- Цель — повысить разборчивость речи и субъективное качество
- Используется best-effort DSP pipeline
- Результат зависит от исходного качества аудио

### Когда инструмент работает плохо
- Очень громкая музыка, перекрывающая речь
- Отсутствие участков тишины для анализа шума
- Сильно искажённое или повреждённое аудио
- Музыка в том же частотном диапазоне, что и речь (300-3400 Hz)

## Архитектура

Решение следует модульной архитектуре пайплайна:

```
Входное видео → Probe → Analysis → Filter Chain → Process → Выходное видео
```

### Модули

#### `pipeline/ffmpeg.py`
Обёртка для выполнения команд ffmpeg/ffprobe с обработкой ошибок и логированием.

#### `pipeline/probe.py`
Извлечение метаданных и статистики из медиафайлов:
- Кодеки видео/аудио
- Sample rate, channels, bit depth
- Длительность

#### `pipeline/analysis.py`
Анализ аудио для определения параметров фильтрации:
- Детекция участков тишины (`silencedetect`)
- Оценка уровня фонового шума
- Оценка уровня речи
- Эвристика определения музыки

#### `pipeline/filters.py`
Построение адаптивных цепочек фильтров на основе анализа и пресета.

#### `pipeline/process.py`
Применение фильтров к аудио с сохранением видео потока и A/V синхронизации.

#### `config.py`
Централизованные пресеты обработки (light, default, aggressive).

#### `main.py`
CLI точка входа с обработкой аргументов и оркестрацией пайплайна.

#### `env_config.py`
Модуль для работы с переменными окружения из `.env` файла.
Использует только стандартную библиотеку Python (без внешних зависимостей).

## Быстрый старт

### Требования
- Docker
- Видеофайлы для обработки

### Зависимости

Проект использует **только стандартную библиотеку Python 3.11+**. Внешние зависимости не требуются.

Файл `requirements.txt` создан для явности и будущего расширения, но сейчас он пуст (только с комментариями).


### Конфигурация через переменные окружения

Вы можете настроить поведение приложения через файл `.env` или системные переменные окружения.

1. **Создайте  файл:**
.env


2. **Отредактируйте `.env`** (файл не попадает в git, см. `.gitignore`)

3. **Доступные переменные:**
   - `LOG_LEVEL` - Уровень логирования (DEBUG, INFO, WARNING, ERROR)
   - `INPUT_DIR` - Путь к директории с входными файлами
   - `OUTPUT_DIR` - Путь к директории для выходных файлов
   - `DEFAULT_PRESET` - Пресет по умолчанию (light, default, aggressive)
   - `FFMPEG_PATH` - Путь к ffmpeg (если не в PATH)
   - `FFPROBE_PATH` - Путь к ffprobe (если не в PATH)
   - `FFMPEG_TIMEOUT` - Таймаут выполнения команд в секундах
   - `MAX_OUTPUT_SIZE_MB` - Максимальный размер выходного файла

**Приоритет настроек:**
1. Аргументы командной строки (высший приоритет)
2. Переменные окружения из `.env` файла
3. Системные переменные окружения
4. Значения по умолчанию

### Использование

#### Вариант 1: Docker (рекомендуется)

1. **Поместите видеофайлы в директорию `fixtures/`**

2. **Соберите Docker образ:**
```bash
docker build -t voice-cleaner .
```

3. **Запустите обработку:**

**Простая команда (копируйте и вставьте):**
```bash
docker run --rm \
  -v $(pwd)/fixtures:/app/fixtures \
  -v $(pwd)/output:/app/output \
  voice-cleaner \
  --input /app/fixtures \
  --output /app/output \
  --preset max_voice
```

**Или используйте готовый скрипт:**
```bash
./DOCKER_RUN.sh
```

**Пример с другими пресетами:**
```bash
# Агрессивная обработка
docker run --rm \
  -v $(pwd)/fixtures:/app/fixtures \
  -v $(pwd)/output:/app/output \
  voice-cleaner \
  --preset aggressive

# Мягкая обработка
docker run --rm \
  -v $(pwd)/fixtures:/app/fixtures \
  -v $(pwd)/output:/app/output \
  voice-cleaner \
  --preset light
```

#### Вариант 2: Локальный запуск

Требуется установленный Python 3.11+ и ffmpeg:

```bash
python3 main.py --input fixtures --output output --preset max_voice
```

### Именование выходных файлов

Выходные файлы автоматически получают имена с пресетом и timestamp:
- Формат: `original_name_[preset]_YYYY-MM-DD_HH-MM-SS.mp4`
- Пример: `video_max_voice_2026-01-09_01-19-16.mp4`

Это позволяет:
- Видеть, какой пресет использовался
- Легко определить последний обработанный файл (по timestamp)
- Хранить несколько версий одного файла с разными пресетами

### Параметры командной строки

- `--input` - Путь к директории с входными видеофайлами (по умолчанию: `fixtures`)
- `--output` - Путь к директории для сохранения обработанных файлов (по умолчанию: `output`)
- `--preset` - Пресет обработки: `light`, `default`, `aggressive` (по умолчанию: `default`)
- `--verbose`, `-v` - Включить подробное логирование (DEBUG уровень)

### Поддерживаемые форматы

Входные форматы: `.mp4`, `.avi`, `.mov`, `.mkv`, `.flv`, `.webm`, `.m4v`

Выходной формат соответствует входному (видео копируется без перекодирования).

## Пресеты

### `light` - Минимальная обработка
- Сохраняет оригинальный характер звука
- Мягкое шумоподавление
- Легкая компрессия
- Подходит для: уже качественного аудио с небольшим шумом

### `default` - Сбалансированная обработка
- Оптимальный баланс качества и обработки
- Среднее шумоподавление
- Умеренная компрессия и частотная коррекция
- Подходит для: большинства случаев, стандартная обработка

### `aggressive` - Максимальное улучшение
- Максимальная разборчивость речи
- Сильное шумоподавление
- Агрессивная компрессия и эквалайзер
- Подходит для: сильно зашумлённого аудио, может добавить артефакты

## Технические детали

### Порядок фильтров (критически важен)

1. **highpass/lowpass** - Убираем ненужные частоты ДО обработки
2. **afftdn** (шумоподавление) - Убираем шум ДО компрессии
3. **acompressor** - Выравниваем динамику
4. **firequalizer** - Частотная коррекция ПОСЛЕ компрессии
5. **alimiter** - Финальное ограничение пиков

### Почему такой порядок?

- Фильтрация частот до шумоподавления уменьшает артефакты
- Шумоподавление до компрессии предотвращает усиление шума
- Компрессия выравнивает уровни перед эквалайзером
- Эквалайзер после компрессии работает с выровненным сигналом
- Лимитер в конце предотвращает клиппинг

### Синхронизация A/V

Для сохранения синхронизации используются:
- `-c:v copy` - Копирование видео без перекодирования
- `-vsync 0` - Отключение автоматической синхронизации видео
- `aresample=async=1` - Асинхронный ресемплинг аудио
- `-shortest` - Обрезка по самому короткому потоку

### Анализ аудио

Инструмент использует:
- **silencedetect** - для поиска участков тишины
- **astats** - для оценки уровней шума и речи

Важно понимать:
- Тишина ≠ шум: тишина - это участки без речи, но там может быть фоновый шум
- Участки тишины (intro/паузы) используются для оценки фонового шума
- Если в файле нет участков тишины, анализ будет менее точным

### Почему не используются neural filters?

- Требуют ML-модели (запрещено по требованиям)
- Требуют интернет-доступ для загрузки моделей
- Медленнее работают
- Наш подход использует только DSP (Digital Signal Processing)

## Возможные артефакты

- **Металлический звук** - от агрессивного шумоподавления
- **Дыхание/пумпинг** - от компрессии
- **Искажения** - от эквалайзера на высоких уровнях
- **Клиппинг** - при неправильной настройке лимитера

Для минимизации артефактов используйте пресет `light` или `default`.

## Будущие улучшения с ML

С использованием ML можно было бы:

1. **Source separation** - Полное разделение речи и музыки
   - Использование моделей типа Spleeter, LALAL.AI
   - Полное удаление музыки без искажения речи

2. **Neural noise reduction** - Нейросетевое шумоподавление
   - Более эффективное, чем DSP фильтры
   - Меньше артефактов

3. **Voice enhancement** - Улучшение качества речи
   - Восстановление потерянных частот
   - Улучшение разборчивости

4. **Adaptive processing** - Адаптивная обработка
   - ML-модели для определения оптимальных параметров
   - Автоматическая настройка под тип контента

## Структура проекта

```
voice_cleaner/
├── Dockerfile              # Docker образ
├── README.md              # Документация
├── requirements.txt        # Зависимости (пустой, только stdlib)
├── main.py                # CLI точка входа
├── config.py             # Пресеты обработки
├── env_config.py          # Работа с переменными окружения
├── .env.example           # Пример файла с переменными окружения
├── pipeline/              # Модули пайплайна
│   ├── __init__.py
│   ├── ffmpeg.py          # Обёртка ffmpeg/ffprobe
│   ├── probe.py           # Извлечение метаданных
│   ├── analysis.py        # Анализ аудио
│   ├── filters.py         # Построение фильтров
│   └── process.py         # Обработка видео
├── fixtures/              # Входные видеофайлы
└── output/                # Обработанные файлы
```

## Разработка

### Локальный запуск (без Docker)

Требуется установленный `ffmpeg` и `ffprobe`:

```bash
python main.py --input fixtures --output output --preset default --verbose
```

### Тестирование

1. Поместите тестовые видеофайлы в `fixtures/`
2. Запустите обработку
3. Проверьте результаты в `output/`
4. Проверьте A/V синхронизацию визуально
5. Проверьте улучшение уровней аудио


